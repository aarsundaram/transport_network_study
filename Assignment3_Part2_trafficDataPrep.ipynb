{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-3 (Part-2): Analyzing Road Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "#import necessary files\n",
    "BMMS=pd.read_csv('BMMS_overview.csv',sep=',')\n",
    "#getting list of unique road names \n",
    "roads_all= pd.read_excel('RMMS/_overview.xls')\n",
    "roads_list=roads_all['road']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scraping Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "n=[]\n",
    "r=[]\n",
    "z=[]\n",
    "filenames=[]\n",
    "merged_df=pd.DataFrame(columns=cols)\n",
    "n_roads=pd.DataFrame(columns=cols)\n",
    "r_roads=pd.DataFrame(columns=cols)\n",
    "z_roads=pd.DataFrame(columns=cols)\n",
    "\n",
    "for filename in glob.glob('RMMS/*.traffic.htm'):\n",
    "    filenames.append(filename)\n",
    "    road_req=re.findall(r'/(.+?).t',filename)\n",
    "    f = open(filename, \"r\")\n",
    "    f1=pd.read_html(f,skiprows=3,header=1,attrs={'class':'clsTbl'})\n",
    "    f1[0]['road']=road_req[0]\n",
    "    merged_df=pd.concat([merged_df,f1[0]])\n",
    "    if(filename[5]=='N'):\n",
    "        n_roads=pd.concat([n_roads,f1[0]])        \n",
    "    elif(filename[5]=='R'):\n",
    "        r_roads=pd.concat([r_roads,f1[0]])                   \n",
    "    else:\n",
    "        z_roads=pd.concat([z_roads,f1[0]])        \n",
    "\n",
    "\n",
    "c=['Unnamed: 0','Unnamed: 1']\n",
    "merged_df=merged_df.dropna(subset=c)\n",
    "n_roads=n_roads.dropna(subset=c)\n",
    "r_roads=r_roads.dropna(subset=c)\n",
    "z_roads=z_roads.dropna(subset=c)\n",
    "\n",
    "merged_df.reset_index(drop=True)\n",
    "n_roads.reset_index(drop=True)\n",
    "r_roads.reset_index(drop=True)\n",
    "z_roads.reset_index(drop=True)\n",
    "\n",
    "#drop non-numeric AADT rows. \n",
    "merged_df = merged_df.replace({'NS':0, '*  NS':0})\n",
    "n_roads = n_roads.replace({'NS':0, '*  NS':0})\n",
    "r_roads = r_roads.replace({'NS':0, '*  NS':0})\n",
    "z_roads = z_roads.replace({'NS':0, '*  NS':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uncomment to write to csv \n",
    "merged_df.to_csv('merged_allroads_traffic.csv')\n",
    "n_roads.to_csv('N_roads.csv')\n",
    "r_roads.to_csv('R_roads.csv')\n",
    "z_roads.to_csv('Z_roads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road</th>\n",
       "      <th>road_segment</th>\n",
       "      <th>road_name</th>\n",
       "      <th>startLRP</th>\n",
       "      <th>endLRP</th>\n",
       "      <th>startChainage</th>\n",
       "      <th>endChainage</th>\n",
       "      <th>road_length</th>\n",
       "      <th>Heavy Truck</th>\n",
       "      <th>Medium Truck</th>\n",
       "      <th>...</th>\n",
       "      <th>Car</th>\n",
       "      <th>Auto Rickshaw</th>\n",
       "      <th>Motor Cycle</th>\n",
       "      <th>Bi-Cycle</th>\n",
       "      <th>Cycle Rickshaw</th>\n",
       "      <th>Cart</th>\n",
       "      <th>Motorized</th>\n",
       "      <th>Non Motorized</th>\n",
       "      <th>Total AADT</th>\n",
       "      <th>AADT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Z3605</td>\n",
       "      <td>Z3605-1</td>\n",
       "      <td>Bhairab-Mendipur</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>LRPE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.278</td>\n",
       "      <td>14.278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Z5707</td>\n",
       "      <td>Z5707-1</td>\n",
       "      <td>Nilphamari-Int.with Z5701</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Z5707</td>\n",
       "      <td>Z5707-2</td>\n",
       "      <td>Int.with Z5701-Int.with Z5709</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>LRP003</td>\n",
       "      <td>0.740</td>\n",
       "      <td>4.039</td>\n",
       "      <td>3.299</td>\n",
       "      <td>75.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>4568.0</td>\n",
       "      <td>4568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Z5707</td>\n",
       "      <td>Z5707-3</td>\n",
       "      <td>Int.with Z5709-Domar</td>\n",
       "      <td>LRP003</td>\n",
       "      <td>LRP021</td>\n",
       "      <td>4.039</td>\n",
       "      <td>21.330</td>\n",
       "      <td>17.291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Z6852</td>\n",
       "      <td>Z6852-1</td>\n",
       "      <td>Manda-Niamatpur (int.with Z6813)</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>LRP017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.950</td>\n",
       "      <td>17.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>3137.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    road road_segment                         road_name startLRP  endLRP  \\\n",
       "0  Z3605      Z3605-1                  Bhairab-Mendipur     LRPS    LRPE   \n",
       "1  Z5707      Z5707-1         Nilphamari-Int.with Z5701     LRPS    LRPS   \n",
       "2  Z5707      Z5707-2     Int.with Z5701-Int.with Z5709     LRPS  LRP003   \n",
       "3  Z5707      Z5707-3              Int.with Z5709-Domar   LRP003  LRP021   \n",
       "4  Z6852      Z6852-1  Manda-Niamatpur (int.with Z6813)     LRPS  LRP017   \n",
       "\n",
       "   startChainage  endChainage  road_length  Heavy Truck  Medium Truck  ...  \\\n",
       "0          0.000       14.278       14.278          0.0           0.0  ...   \n",
       "1          0.000        0.740        0.740          0.0           0.0  ...   \n",
       "2          0.740        4.039        3.299         75.0         128.0  ...   \n",
       "3          4.039       21.330       17.291          0.0           0.0  ...   \n",
       "4          0.000       17.950       17.950          0.0         109.0  ...   \n",
       "\n",
       "    Car  Auto Rickshaw  Motor Cycle  Bi-Cycle  Cycle Rickshaw  Cart  \\\n",
       "0   0.0            0.0          0.0       0.0             0.0   0.0   \n",
       "1   0.0            0.0          0.0       0.0             0.0   0.0   \n",
       "2  19.0          294.0       1307.0    1845.0           542.0   0.0   \n",
       "3   0.0            0.0          0.0       0.0             0.0   0.0   \n",
       "4  17.0          854.0        895.0     771.0           337.0   0.0   \n",
       "\n",
       "   Motorized  Non Motorized  Total AADT    AADT  \n",
       "0        0.0            0.0         0.0     0.0  \n",
       "1        0.0            0.0         0.0     0.0  \n",
       "2     2181.0         2387.0      4568.0  4568.0  \n",
       "3        0.0            0.0         0.0     0.0  \n",
       "4     2029.0         1108.0      3137.0  3137.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the merged traffic data for use. \n",
    "#drop columns\n",
    "merged_traffic=pd.read_csv('merged_allroads_traffic.csv')\n",
    "merged_traffic= merged_traffic.drop(columns=['Unnamed: 0','Offset','Offset.1'])\n",
    "\n",
    "#rename columns\n",
    "merged_traffic=merged_traffic.rename({'Unnamed: 0.1':'road_segment','Unnamed: 1':'road_name','LRP':'startLRP','Chainage':'startChainage','LRP.1':'endLRP','Chainage.1':'endChainage','(Km)':'road_length','(AADT)':'AADT'},axis=1)\n",
    "\n",
    "#convert all numbers to float\n",
    "cols_list=['road','road_segment', 'road_name', 'startLRP', 'endLRP', 'startChainage',\n",
    "       'endChainage', 'road_length', 'Heavy Truck', 'Medium Truck',\n",
    "       'Small Truck', 'Large Bus', 'Medium Bus', 'Micro Bus', 'Utility', 'Car',\n",
    "       'Auto Rickshaw', 'Motor Cycle', 'Bi-Cycle', 'Cycle Rickshaw', 'Cart',\n",
    "       'Motorized', 'Non Motorized', 'Total AADT', 'AADT']\n",
    "merged_traffic=merged_traffic[cols_list]   #rearrange columns for ease of conversion\n",
    "merged_traffic.iloc[:,6:]=merged_traffic.iloc[:,6:].astype(float)\n",
    "\n",
    "merged_traffic.to_csv('merged_allroads_traffic.csv')\n",
    "\n",
    "merged_traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape LRP data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse all road LRPs into one file \n",
    "import re\n",
    "filenames=[]\n",
    "m=[]\n",
    "merged_lrps=pd.DataFrame(columns=cols)\n",
    "for filename in glob.glob('RMMS/*.lrps.htm'):\n",
    "    filenames.append(filename)\n",
    "    road_req=re.findall(r'/(.+?).l',filename)\n",
    "    f = open(filename, \"r\")\n",
    "    f1=pd.read_html(f,skiprows=3,header=0,attrs={'class':'clsTbl'})\n",
    "    f1[0]['road']=road_req[0]\n",
    "    m.append(f1[0])\n",
    "    merged_lrps=pd.concat([merged_lrps,f1[0]])\n",
    "    \n",
    "    \n",
    "#write to csv <uncomment if needed>\n",
    "merged_lrps.to_csv('all_road_lrps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scrape Widths Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parse all width text files from RMMS\n",
    "\n",
    "#create empty dataframe for merging resultant csvs\n",
    "w_cols=['roadNo', 'roadId', 'startChainage', 'endChainage', 'width', 'nrLanes','road']\n",
    "filenames=[]\n",
    "widths=pd.DataFrame(columns=w_cols)\n",
    "\n",
    "#parse through every .txt file in RMMS\n",
    "for filename in glob.glob('RMMS/*.widths.processed.txt'):\n",
    "    \n",
    "    #get road name \n",
    "    filenames.append(filename)\n",
    "    road_req=re.findall(r'/(.+?).w',filename)\n",
    "    \n",
    "    #read text file\n",
    "    road_width=pd.read_csv(filename,sep='\\t')\n",
    "    #add column with road name \n",
    "    road_width['road']=road_req[0]\n",
    "    #merge with main widths file\n",
    "    widths=pd.concat([widths,road_width])\n",
    "\n",
    "    \n",
    "#write to csv <uncomment if needed>\n",
    "widths.to_csv('all_road_widths.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding number of lanes for each road segment from the widths dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_traffic=pd.read_csv('merged_allroads_traffic.csv')\n",
    "merged_traffic=merged_traffic.drop(columns=['Unnamed: 0'])\n",
    "#merged_traffic.head()\n",
    "\n",
    "\n",
    "merged_traffic=merged_traffic.replace({'nan':0})\n",
    "merged_traffic['nrLanes']=0\n",
    "merged_traffic['startChainage']=merged_traffic['startChainage']+0.0001\n",
    "#merged_traffic['width']=0\n",
    "nr_roads=[]\n",
    "nr_values=[]\n",
    "nr_segments=[]\n",
    "#nr_widths=[]\n",
    "for road in roads_list:\n",
    "    m_subset=merged_traffic.loc[merged_traffic['road']==road,['road_segment','endChainage']]\n",
    "    m_subset['nrLanes']=0\n",
    "    m_indexes=list(m_subset['road_segment'].index)\n",
    "    m_chainage=list(m_subset['endChainage'])\n",
    "    w_subset= widths.loc[widths['road']==road,['road','startChainage','endChainage','width','nrLanes']]\n",
    "    w_subset.reset_index(drop=True)     #so that we can run through with a for loop\n",
    "    \n",
    "    for i in m_indexes: #for each chainage value, you run through the widths and check if it lies in difference\n",
    "        \n",
    "        for j in list(w_subset.index):  #uses index to run through the subset of widths data\n",
    "           \n",
    "            start_chain=w_subset.loc[j,'startChainage']\n",
    "            end_chain=w_subset.loc[j,'endChainage']\n",
    "            req_val= m_subset.loc[i,'endChainage']\n",
    "            \n",
    "            \n",
    "            if(start_chain<= req_val <=end_chain):\n",
    "                nr_values.append(w_subset.loc[j,'nrLanes'])\n",
    "                #nr_widths.append(w_subset.loc[j,'width'])\n",
    "                nr_roads.append(road)\n",
    "                nr_segments.append(m_subset.loc[i,'road_segment'])\n",
    "                \n",
    "#df.loc[(df.Event == 'Dance'),'Event']='Hip-Hop'\n",
    "            \n",
    "        \n",
    "\n",
    "#adding the nrLanes values we obtained, to main data set\n",
    "nr_values=pd.Series(nr_values)\n",
    "nr_roads=pd.Series(nr_roads)\n",
    "nr_segments=pd.Series(nr_segments)\n",
    "#nr_widths=pd.Series(nr_widths)\n",
    "x=pd.concat([nr_values,nr_roads,nr_segments],axis=1)\n",
    "x.columns=['nrLanes','road','road_segment']\n",
    "x=x.drop(columns=['road'])\n",
    "x=x.drop_duplicates(subset=['road_segment'],keep='first')\n",
    "\n",
    "for i in list(merged_traffic.index):\n",
    "    road_seg=merged_traffic.loc[i,'road_segment']\n",
    "    nr_val=list(x.loc[x['road_segment']==road_seg,'nrLanes'])\n",
    "    #nr_width_val=x.loc[x['road_segment']==road_seg,'width']\n",
    "    if(len(nr_val)==1):\n",
    "        merged_traffic.loc[i,'nrLanes']=nr_val[0]\n",
    "    #merged_traffic.loc[i,'width']=nr_width_val\n",
    "        \n",
    "\n",
    "#uncomment if required\n",
    "#merged_traffic.to_csv('merged_traffic_with_nrlanes.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating traffic density by mode of transport\n",
    "\n",
    "The following values of PCE (Passenger Car Equivalents) were used for calculating density: \n",
    "\n",
    "    pce_trucks= 3\n",
    "    pce_bus= 2.16\n",
    "    pce_microbus= 1.42\n",
    "    pce_auto = 0.86\n",
    "    pce_motorcycle=0.8\n",
    "    pce_nonmotor=0.6 \n",
    "\n",
    "    Traffic Density = Number of PCE of mode of transport / (no. of lanes * length of road segment) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns \n",
    "merged=pd.read_csv('merged_traffic_with_nrlanes.csv')\n",
    "merged.reset_index(drop=True)\n",
    "merged=merged.drop(columns='Unnamed: 0')\n",
    "merged['trucks_density']=0\n",
    "merged['bus_density']=0\n",
    "merged['car_density']=0\n",
    "merged['mot_density']=0\n",
    "merged['nonmotorized_density']=0\n",
    "\n",
    "#pce values \n",
    "pce_trucks= 3\n",
    "pce_bus= 2.16\n",
    "pce_microbus= 1.42\n",
    "pce_auto = 0.86\n",
    "pce_motorcycle=0.8\n",
    "pce_nonmotor=0.6\n",
    "\n",
    "\n",
    "#calculate truck density\n",
    "#truck density = sum of (['Heavy Truck','Medium Truck', 'Small Truck']*pce_trucks)/(nrLanes*length)\n",
    "for i in list(merged.index):\n",
    "    sum_trucks= (merged.loc[i,'Heavy Truck'])+(merged.loc[i,'Medium Truck'])+(merged.loc[i,'Small Truck'])\n",
    "    denom= (merged.loc[i,'nrLanes']) * (merged.loc[i,'road_length'])\n",
    "    density_truck = (sum_trucks*pce_trucks)/denom\n",
    "    merged.loc[i,'trucks_density']=density_truck\n",
    "\n",
    "i=0\n",
    "#calculate buses density \n",
    "#['Large Bus', 'Medium Bus', 'Micro Bus']\n",
    "for i in list(merged.index):\n",
    "    sum_bus= (merged.loc[i,'Large Bus'])+(merged.loc[i,'Medium Bus'])+(merged.loc[i,'Micro Bus'])\n",
    "    denom= (merged.loc[i,'nrLanes']) * (merged.loc[i,'road_length'])\n",
    "    density_bus = (sum_bus*pce_bus)/denom\n",
    "    merged.loc[i,'bus_density']=density_bus\n",
    "\n",
    "i=0\n",
    "#calculate car density \n",
    "#['Car']\n",
    "for i in list(merged.index):\n",
    "    sum_car= (merged.loc[i,'Car'])\n",
    "    denom= (merged.loc[i,'nrLanes']) * (merged.loc[i,'road_length'])\n",
    "    density_car = (sum_car)/denom\n",
    "    merged.loc[i,'car_density']=density_car\n",
    "    \n",
    "    \n",
    "i=0\n",
    "#calculate motorcycle density \n",
    "#['Motor Cycle']\n",
    "for i in list(merged.index):\n",
    "    sum_mot= (merged.loc[i,'Motor Cycle'])\n",
    "    denom= (merged.loc[i,'nrLanes']) * (merged.loc[i,'road_length'])\n",
    "    density_mot = (sum_mot*pce_motorcycle)/denom\n",
    "    merged.loc[i,'mot_density']=density_mot\n",
    "    \n",
    "i=0\n",
    "#calculate non-motorized density \n",
    "#['Non Motorized']\n",
    "for i in list(merged.index):\n",
    "    sum_nonmot= (merged.loc[i,'Non Motorized'])\n",
    "    denom= (merged.loc[i,'nrLanes']) * (merged.loc[i,'road_length'])\n",
    "    density_nonmot = (sum_nonmot*pce_nonmotor)/denom\n",
    "    merged.loc[i,'nonmotorized_density']=density_nonmot\n",
    "    \n",
    "    \n",
    "merged=merged.sort_values('road')\n",
    "#merged.to_csv('merged_withdensities.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Assigning latitude and longitude values for road segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read necessary files\n",
    "roads_only=pd.read_csv('roads_only.csv')\n",
    "roads_only=roads_only.drop(columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','Unnamed: 7'])\n",
    "roads_only=roads_only.rename(columns={'Latitude Decimal':'lat','Longitued Decimal':'lon'})\n",
    "\n",
    "\n",
    "merged=pd.read_csv('merged_withdensities.csv')\n",
    "merged2=merged\n",
    "merged2=merged2.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "merged2=merged\n",
    "#creating 2 new columns to insert lat and lon values\n",
    "merged2['lat']=0\n",
    "merged2['lon']=0   #remember to replace these 0s with NaN to avoid points at equator for empty rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road LRPs and spatial data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Road points dataset\")\n",
    "roads_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merged Data Set\")\n",
    "merged2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding latitude and longitude values from roadLRP dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get roadwise subsets for both merged2 and roads_only\n",
    "\n",
    "#roadwise subset:\n",
    "for road in roads_list:\n",
    "    mr_subset=merged2.loc[merged2['road']==road]  #subset from merged data\n",
    "    r_subset= roads_only.loc[roads_only['road']==road,['road','Road Chainage','lat','lon']]\n",
    "    \n",
    "    for i in list(mr_subset.index):  #get indices so that we can replace with value in the main dataset itself\n",
    "        m_endchain= mr_subset.loc[i,'endChainage']\n",
    "        req_lat= list(r_subset.loc[r_subset['Road Chainage']==m_endchain,'lat'])\n",
    "        req_lon= list(r_subset.loc[r_subset['Road Chainage']==m_endchain,'lon'])\n",
    "        \n",
    "        #replace values in the main dataset with index i\n",
    "        if(len(req_lat)==1):\n",
    "            merged2.loc[i,'lat']=req_lat[0]\n",
    "        if(len(req_lon)==1):\n",
    "            merged2.loc[i,'lon']=req_lon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing to csv, uncomment if needed\n",
    "merged_final=merged2\n",
    "#to_csv\n",
    "#merged_final.to_csv('merged_withlatlonvalues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scraping data from divisions.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse all divisions.htm into one file \n",
    "import re\n",
    "new_cols=['Division', 'startLRP', 'Offset', 'startChainage', 'endLRP', 'Offset.1',\n",
    "       'endChainage', 'road_length','road']\n",
    "filenames=[]\n",
    "m=[]\n",
    "merged_div=pd.DataFrame(columns=new_cols)\n",
    "for filename in glob.glob('RMMS/*.divisions.htm'):\n",
    "    filenames.append(filename)\n",
    "    road_req=re.findall(r'/(.+?).d',filename)\n",
    "    f = open(filename, \"r\")\n",
    "    f1=pd.read_html(f,skiprows=3,header=1,attrs={'class':'clsTbl'})\n",
    "    #DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)[source]\n",
    "    f1[0]=f1[0].dropna(axis=0,how='all')\n",
    "    f1[0]['road']=road_req[0]\n",
    "    f1[0].columns=new_cols\n",
    "    #m.append(f1[0])\n",
    "    merged_div=pd.concat([merged_div,f1[0]])\n",
    "    \n",
    "merged_div=merged_div.sort_values('road')    \n",
    "#write to csv <uncomment if needed>\n",
    "#merged_div.to_csv('all_roads_divisions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculating vulerability weights for each road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating vulnerability weights for roads based on how much of the road lies in a vulnerable zone\n",
    "merged_div['Province']=' '\n",
    "#adding province information\n",
    "merged_div.loc[merged_div['Division'].isin(['Barguna','Barisal','Bhola','Jhalokati',\n",
    "                                              'Patuakhali','Pirojpur']),'Province'] = 'Barisal'\n",
    "merged_div.loc[merged_div['Division'].isin(['Bandarban','Brahmanbaria','Chandpur',\n",
    "                                              'Chittagong','Comilla',\"Cox's Bazar\",\n",
    "                                              'Feni','Khagrachari','Laxmipur','Noakhali',\n",
    "                                              'Rangamati','Dohazari']),'Province'] = 'Chittagong'\n",
    "merged_div.loc[merged_div['Division'].isin(['Dhaka','Faridpur','Gazipur','Gopalganj',\n",
    "                                              'Kishoreganj','Madaripur','Manikganj','Munshiganj',\n",
    "                                              'Narayanganj','Narsingdi','Rajbari','Sariatpur',\n",
    "                                              'Tangail']),'Province'] = 'Dhaka'\n",
    "merged_div.loc[merged_div['Division'].isin(['Mymensingh','Jamalpur','Sherpur','Netrokona']),'Province'] = 'Mymensingh'\n",
    "merged_div.loc[merged_div['Division'].isin(['Bagerhat','Chuadanga','Jessore','Jhenaidah',\n",
    "                                              'Khulna','Kushtia','Magura','Meherpur','Narail',\n",
    "                                              'Satkhira']),'Province'] = 'Khulna'\n",
    "merged_div.loc[merged_div['Division'].isin(['Bogra','Joypurhat','Naogaon','Natore','Nawabganj',\n",
    "                                              'Pabna','Rajshahi','Sirajganj']),'Province'] = 'Rajshahi'\n",
    "merged_div.loc[merged_div['Division'].isin(['Rangpur','Nilphamari','Dinajpur','Panchgarh',\n",
    "                                              'Gaibanda','Kurigram','Lalmonirhat','Thakurgaon']),'Province'] = 'Rangpur'\n",
    "merged_div.loc[merged_div['Division'].isin(['Habiganj','Moulavi Bazar','Sunamganj','Sylhet']),'Province'] = 'Sylhet'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vulnerability calculation for road\n",
    "\n",
    "The vulnerability weight in this doc is roadwise, factoring in its location as disaster exposure is the main\n",
    "criteria for a road being vulnerable or not. For example: \n",
    "    \n",
    "         Vulnerability weight for N1 = Sum of [(length of road in district A)*(vulnerability of district A)] \n",
    "        \n",
    "By this formula, the longer a stretch of a road is in a disaster-risk area, the more vulnerable its score \n",
    "will be.  \n",
    "    \n",
    "\n",
    "### Vulnerability calculation for a road-segment\n",
    "\n",
    "The more number of lanes a road-segment has and the longer it is, the more parts of it and the vehicle travelling in that road-segment\n",
    "will be exposed to disaster-risk and hence will be vulnerable. \n",
    "\n",
    "Therefore, the logic for calculating for vulnerability for every road-segment will be: \n",
    "    \n",
    "        Vulnerability weight for N1-1L = number of lanes of road-segment * vulnerability-weight * length of roadseg \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vulnerability weights \n",
    "Barisal= 0.2359917486\n",
    "Chittagong = 0.09950670221\n",
    "Dhaka= 0.21122947\n",
    "Khulna= 0.09709530567\n",
    "Rajshahi = 0.131646117\n",
    "Rangpur = 0.1106154519\n",
    "Sylhet = 0.1139152045\n",
    "Mymensingh = 0\n",
    "\n",
    "merged_div['province_weight']=0\n",
    "merged_div=merged_div.reset_index(drop=True)\n",
    "#the end goal here is to result in a dataframe where you have road & its vulnerability weight\n",
    "\n",
    "for i in list(merged_div.index):\n",
    "    div=merged_div.loc[i,'Province']\n",
    "    if(div=='Barisal'):\n",
    "        merged_div.loc[i,'province_weight']=Barisal\n",
    "    elif(div=='Chittagong'):\n",
    "        merged_div.loc[i,'province_weight']=Chittagong\n",
    "    elif(div=='Dhaka'):\n",
    "        merged_div.loc[i,'province_weight']=Dhaka\n",
    "    elif(div=='Khulna'):\n",
    "        merged_div.loc[i,'province_weight']=Khulna\n",
    "    elif(div=='Rajshahi'):\n",
    "        merged_div.loc[i,'province_weight']=Rajshahi\n",
    "    elif(div=='Rangpur'):\n",
    "        merged_div.loc[i,'province_weight']=Rangpur\n",
    "    elif(div=='Sylhet'):\n",
    "        merged_div.loc[i,'province_weight']=Sylhet\n",
    "    else:\n",
    "        merged_div.loc[i,'province_weight']=0\n",
    "\n",
    "#get road subsets to calculate weighted vulnerability (with road length)\n",
    "vul_weight=[]\n",
    "vul_road=[]\n",
    "for road in roads_list:\n",
    "    road_subset=merged_div.loc[merged_div['road']==road]\n",
    "    cal=0\n",
    "    for j in list(road_subset.index):\n",
    "        w=0\n",
    "        w=road_subset.loc[j,'province_weight']*road_subset.loc[j,'road_length']\n",
    "        cal=cal+w\n",
    "    vul_weight.append(cal)\n",
    "    vul_road.append(road)\n",
    "\n",
    "vul_weight=pd.Series(vul_weight)\n",
    "vul_road=pd.Series(vul_road)\n",
    "\n",
    "vul_df=pd.concat([vul_road,vul_weight],axis=1)\n",
    "vul_df=vul_df.rename(columns={0:'road',1:'vulnerability_weight'})\n",
    "vul_df.head()\n",
    "\n",
    "#vul_df.to_csv('roadwise_vulnerabilityweights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding to the main dataset\n",
    "merged2=merged2.drop(columns=['Unnamed: 0'])\n",
    "merged2['vulnerability_weight']=0\n",
    "\n",
    "for i in list(merged2.index):\n",
    "    m_road=merged2.loc[i,'road']\n",
    "    vul_weight=list(vul_df.loc[vul_df['road']==m_road,'vulnerability_weight'])\n",
    "    \n",
    "    #assign the weight you got to the merged2 dataset\n",
    "    merged2.loc[i,'vulnerability_weight']=vul_weight[0]\n",
    "\n",
    "merged_final_withvul=merged2\n",
    "#write to csv\n",
    "#merged_final_withvul.to_csv('merged_withvulnerabilityweights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column for vulnerability for road_segment: \n",
    "merged_final_withvul['vul_roadseg']=0\n",
    "\n",
    "for i in list(merged_final_withvul.index):\n",
    "    nrlanes= merged_final_withvul.loc[i,'nrLanes']\n",
    "    vul_weight= merged_final_withvul.loc[i,'vulnerability_weight']\n",
    "    length_roadseg=merged_final_withvul.loc[i,'road_length']\n",
    "    merged_final_withvul.loc[i,'vul_roadseg']=nrlanes*vul_weight*length_roadseg\n",
    "    \n",
    "merged_final_withvul.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculating Criticality values\n",
    "\n",
    "The criticality definition used in this study is defined as a function of the importance of the road. \n",
    "This is determined by four factors: \n",
    "    1. More the number of lanes that a road-segment has, the more important it is. \n",
    "    2. National roads (N) are considered more important and critical to the transport infrastructure than Regional roads (R), which are higher in importance to Zilla roads (Z). Rank-reciprocal function and normalization are used to determine the weights for these. \n",
    "    3. Since the criticality study is done to determine which are the roads that are critical for disaster-humanitarian-logistics, where in the event of a disaster trucks are the mode of transport preferred to transport humanitarian aid to the affected districts, the Truck Density is also used in calculation of criticality of road-segment. More the number of trucks that use a particular road-segment, the more critical it is. \n",
    "    4. Longer the road, the more critical it is, as if a long road breaks down, the consequences are higher: the delay is longer, the truck is further away from the target area for humanitarian aid. \n",
    "    \n",
    "    \n",
    "        Criticality of road-segment = (No of lanes)*(road_length)*(N/R/Z Type)*(Truck Density) \n",
    "        \n",
    "   \n",
    "\n",
    "Road weights are determined as follows:\n",
    "\n",
    "        Road  Importance   Weight \n",
    "        N\t3\t0.5\n",
    "        R\t2\t0.3333333333\n",
    "        Z\t1\t0.1666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column for criticality\n",
    "merged_critical = merged_final_withvul \n",
    "merged_critical['criticality']=0\n",
    "\n",
    "#resetting index: \n",
    "merged_critical=merged_critical.reset_index(drop=True)\n",
    "\n",
    "#looping through and getting required values: \n",
    "for i in list(merged_critical.index):\n",
    "    \n",
    "    #getting all required values\n",
    "    nr_lanes= merged_critical.loc[i,'nrLanes']\n",
    "    road_length=merged_critical.loc[i,'road_length']\n",
    "    road_type= merged_critical.loc[i,'road'][0]\n",
    "   \n",
    "    if(road_type=='N'):\n",
    "        road_weight= 0.5\n",
    "    if(road_type=='R'):\n",
    "        road_weight= 0.3\n",
    "    if(road_type=='Z'):\n",
    "        road_weight= 0.167\n",
    "    \n",
    "    truck_density= merged_critical.loc[i,'trucks_density']\n",
    "    \n",
    "    #applying formula \n",
    "    criticality = nr_lanes*road_length*road_weight*truck_density \n",
    "    \n",
    "    #setting the value in the main dataframe \n",
    "    merged_critical.loc[i,'criticality']=criticality\n",
    "\n",
    "#merged_critical.to_csv('merged_final_roads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_critical.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
